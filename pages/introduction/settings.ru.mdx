# Настройки LLM

При работе с промптами вы взаимодействуете с LLM с помощью API или непосредственно. Вы можете настроить несколько параметров, чтобы получить различные результаты для ваших промптов.

**Температура** - Вкратце, чем ниже значение `температуры`, тем более детерминированными будут результаты в смысле того, что будет выбрано самое вероятное следующее токен. Увеличение температуры может привести к большей случайности, что способствует более разнообразным или творческим результатам. Вы фактически увеличиваете веса других возможных токенов. В плане применения, для задач, связанных с ответами на вопросы на основе фактов, рекомендуется использовать более низкое значение температуры, чтобы стимулировать более точные и краткие ответы. Для генерации стихов или других творческих задач может быть полезно увеличить значение температуры.

**Top_p** - Аналогично, с помощью `top_p`, техники сэмплирования с использованием температуры, называемой сэмплированием ядра, вы можете контролировать, насколько детерминированной будет модель в генерации ответа. Если вы ищете точные и фактические ответы, установите низкое значение. Если вы ищете более разнообразные ответы, увеличьте значение.

Общая рекомендация заключается в том, чтобы изменять только один параметр, а не оба.

Перед тем, как перейти к некоторым простым примерам, имейте в виду, что ваши результаты могут отличаться в зависимости от версии LLM, которую вы используете.